{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# image manipulation\n",
    "from PIL import Image\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#tensorflow\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = os.path.join(os.path.expanduser('~'), 'Downloads', 'images')\n",
    "target_size = (224, 224)\n",
    "resized_images = []\n",
    "image_names = []\n",
    "\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        file_path = os.path.join(image_dir, filename)\n",
    "        image = Image.open(file_path)\n",
    "    \n",
    "        rgb_image = image.convert('RGB') # converts image to RGB (jpg -> RGB, png -> RGBA)\n",
    "        resized_image = rgb_image.resize(target_size)\n",
    "        \n",
    "        resized_images.append(resized_image) #records resized images\n",
    "        image_names.append(filename[:-4]) #records names of resized images\n",
    "        \n",
    "print(f'âœ… Resized {len(resized_images)} images in total!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_arr = []\n",
    "for image in resized_images:\n",
    "    images_arr.append(np.array(image))\n",
    "    \n",
    "images_arr = np.array(images_arr)\n",
    "images_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.path.expanduser('~'), 'code', 'jackanichp', 'pill_pic', 'data_collection', 'directory_consumer_grade_images.xlsx')\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "#Create a dataframe using only the images that were downloaded and resized\n",
    "image_names = [int(name) for name in image_names] #convert image names to int\n",
    "index_exists = data.index.isin(image_names) #create a boolean index of the image names that exist in the dataframe\n",
    "data = data.loc[index_exists] #create a new dataframe with only the images that have been resized\n",
    "data.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many images are there for each pill?\n",
    "data['Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder() # Instanciate One hot encoder\n",
    "encoder.fit(data[['NDC11']])\n",
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['encoded_NDC11'] = encoder.fit_transform(data[['NDC11']])\n",
    "data['encoded_NDC11'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization of pixel values to be between 0 and 1\n",
    "images_arr = images_arr / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(images_arr, data['encoded_NDC11'], test_size=0.3)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3) \n",
    "\n",
    "print(f'X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\\nX_val shape: {X_val.shape}, y_val shape: {y_val.shape}\\nX_test shape: {X_test.shape}, y_test shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train.values)\n",
    "y_val = to_categorical(y_val.values)\n",
    "y_test = to_categorical(y_test.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pill_pic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
